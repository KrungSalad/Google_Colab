{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab_ML_3_JN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMxB8t35bx6UYkNJtX++Y3r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KrungSalad/Google_Colab/blob/master/Lab_ML_3_JN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-Ff0ghnW_Xs",
        "colab_type": "code",
        "outputId": "8815e893-3b0b-4d34-eed4-3cb586c593de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "! pip install keras"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.12.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.8)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.18.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ybowb9UOemqj",
        "colab_type": "code",
        "outputId": "2e3a8d8e-07eb-4e86-c405-f3a24ae6deba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "%tensorflow_version 1.4"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.4`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f01EwKRxewpM",
        "colab_type": "code",
        "outputId": "f1166fed-30d4-4036-94df-9c4339fd256e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow\n",
        "print(tensorflow.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JU8y8dTGXBnq",
        "colab_type": "code",
        "outputId": "8390d285-c124-4253-bd6b-30665798c75c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "\n",
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import train_test_split,\\\n",
        "    StratifiedKFold, GridSearchCV\n",
        "from sklearn.metrics import classification_report, \\\n",
        "    confusion_matrix\n",
        "\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import LSTM, Flatten, Dropout\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "import tensorflow\n",
        "\n",
        "# for heatmap purpose\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcSQeLUuXKj7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.options.display.width = None\n",
        "pd.options.display.max_rows = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U38ukHVmXOwz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Chengdu = pd.read_csv('ChengduPM20100101_20151231.csv')\n",
        "dfChengdu = pd.DataFrame(Chengdu)\n",
        "Shenyang = pd.read_csv('ShenyangPM20100101_20151231.csv')\n",
        "dfShenyang = pd.DataFrame(Shenyang)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-o0NO5J4XmQH",
        "colab_type": "code",
        "outputId": "b9761334-963a-4531-88c3-d1766299a54d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "t1 = pd.to_datetime(dfChengdu[['year','month','day','hour']])\n",
        "t2 = pd.to_datetime(dfShenyang[['year','month','day','hour']])\n",
        "\n",
        "dfChengdu = dfChengdu[['PM_US Post','HUMI','Iws','Iprec']]\n",
        "dfShenyang = dfShenyang[['PM_US Post','HUMI','Iws','Iprec']]\n",
        "dfChengdu['Time'] = t1\n",
        "dfShenyang['Time'] = t2\n",
        "\n",
        "dfChengdu = dfChengdu.fillna(dfChengdu.mean())\n",
        "dfChengdu =dfChengdu.interpolate(method='polynomial', order=2)\n",
        "dfShenyang = dfShenyang.fillna(dfShenyang.mean())\n",
        "dfShenyang = dfShenyang.interpolate(method='polynomial', order=2)\n",
        "\n",
        "print(dfChengdu)\n",
        "Chengdu = dfChengdu[['PM_US Post','HUMI','Iws','Iprec']].to_numpy()\n",
        "chx, chy = Chengdu.shape "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YB0b7WdeXtkk",
        "colab_type": "code",
        "outputId": "5453ff42-b84e-45e9-ea0e-b8cf504b8fc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        }
      },
      "source": [
        "#choose  time step=3 stride=2\n",
        "\n",
        "timeSeries = []\n",
        "stack = []\n",
        "for i in range(chx):\n",
        "    ele = []\n",
        "    l = []\n",
        "    for j in range(chy):\n",
        "        l.append(Chengdu[i][j])\n",
        "    stack.append(l)\n",
        "stack = np.array(stack)\n",
        "print(stack, stack.shape)\n",
        "k = 0\n",
        "while k<chx-6 :\n",
        "    t1 = []\n",
        "    for j in range(3):\n",
        "        if k+j < chx:\n",
        "            t1.append(stack[k+j])\n",
        "    timeSeries.append(t1)\n",
        "    k += 2\n",
        "\n",
        "\n",
        "timeSeries = np.array(timeSeries)\n",
        "print(timeSeries, timeSeries.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 83.40761246  81.2          1.           0.        ]\n",
            " [ 83.40761246  86.99         1.           0.        ]\n",
            " [ 83.40761246  86.99         1.           0.        ]\n",
            " ...\n",
            " [213.          87.28         1.           0.        ]\n",
            " [236.          93.4          2.           0.        ]\n",
            " [249.          93.4          4.           0.        ]] (52584, 4)\n",
            "[[[ 83.40761246  81.2          1.           0.        ]\n",
            "  [ 83.40761246  86.99         1.           0.        ]\n",
            "  [ 83.40761246  86.99         1.           0.        ]]\n",
            "\n",
            " [[ 83.40761246  86.99         1.           0.        ]\n",
            "  [ 83.40761246  86.89         1.           0.        ]\n",
            "  [ 83.40761246  86.79         1.           0.        ]]\n",
            "\n",
            " [[ 83.40761246  86.79         1.           0.        ]\n",
            "  [ 83.40761246  93.13         1.           0.        ]\n",
            "  [ 83.40761246  93.13         1.           0.        ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[230.          87.28         1.           0.        ]\n",
            "  [280.          81.61         1.           0.        ]\n",
            "  [302.          81.61         2.           0.        ]]\n",
            "\n",
            " [[302.          81.61         2.           0.        ]\n",
            "  [283.          81.61         2.           0.        ]\n",
            "  [280.          87.28         3.           0.        ]]\n",
            "\n",
            " [[280.          87.28         3.           0.        ]\n",
            "  [298.          87.28         5.           0.        ]\n",
            "  [298.          87.28         1.           0.        ]]] (26289, 3, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptltS7z7Xzbl",
        "colab_type": "code",
        "outputId": "dbef489f-7caa-4951-b3d4-8a8593ce049e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "# prepare groud truth by majority vote\n",
        "# and one-hot encoding (for y)\n",
        "\n",
        "def find_majority(votes):\n",
        "    vote_count = Counter(votes)\n",
        "    top_two = vote_count.most_common(2)\n",
        "    if len(top_two)>1 and top_two[0][1] == top_two[1][1]:\n",
        "        # It is a tie\n",
        "        return 0\n",
        "    return top_two[0][0]\n",
        "#print(timeSeries[1][3][0])\n",
        "dx, dy, dz = timeSeries.shape\n",
        "y = []\n",
        "for i in range(dx):\n",
        "    l = []\n",
        "    for j in range(dy):\n",
        "        if timeSeries[i][j][0] < 10:\n",
        "            l.append(0)\n",
        "        elif timeSeries[i][j][0] < 25:\n",
        "            l.append(1)\n",
        "        else:\n",
        "            l.append(2)\n",
        "    mjr = find_majority(l)\n",
        "    x = [0, 0, 0]\n",
        "    x[mjr] = 1\n",
        "    y.append(x)\n",
        "\n",
        "X = timeSeries\n",
        "y = np.array(y)\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0 1]\n",
            " [0 0 1]\n",
            " [0 0 1]\n",
            " ...\n",
            " [0 0 1]\n",
            " [0 0 1]\n",
            " [0 0 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fP8uSC1X-YA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(\\\n",
        "    X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(\\\n",
        "    X_val, y_val, test_size=0.3, random_state=42)\n",
        "\n",
        "X_train2 = X_train\n",
        "y_train2 = y_train\n",
        "X_val2 = X_val\n",
        "y_val2 = y_val\n",
        "X_test2 = X_test\n",
        "y_test2 = y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvcaj9SLYITC",
        "colab_type": "text"
      },
      "source": [
        "# Section 2\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkTSJ3HJYC_1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def model1func(optimizer='adam'):\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(5, kernel_size=(3,3),\\\n",
        "        activation='relu', input_shape=(3, 4, 1),\\\n",
        "        padding='same'))\n",
        "    model.add(MaxPooling2D(pool_size=(3,3)))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(5, activation= 'relu'))\n",
        "    model.add(Dense(3, activation='sigmoid'))\n",
        "    model.summary()\n",
        "\n",
        "    model.compile( loss='categorical_crossentropy',\\\n",
        "    optimizer='Adam', metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXecGdSLYM_H",
        "colab_type": "code",
        "outputId": "86c722ee-3959-43e9-9415-9a437e744cf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# have to change to 4 dimensions\n",
        "a, b, c = X_train.shape\n",
        "X_train = X_train.reshape([a, b, c, 1])\n",
        "\n",
        "a, b, c = X_val.shape\n",
        "X_val = X_val.reshape([a, b, c, 1])\n",
        "\n",
        "model = model1func()\n",
        "history = model.fit(X_train, y_train,\\\n",
        "    batch_size=3,\\\n",
        "    validation_data=(X_val, y_val),\\\n",
        "    epochs=2)\n",
        "\n",
        "a, b, c = X_test.shape\n",
        "X_test = X_test.reshape([a, b, c, 1])\n",
        "y_prediction = model. predict(X_test)\n",
        "\n",
        "print(y_prediction)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 3, 4, 5)           50        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 1, 1, 5)           0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1, 1, 5)           0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 5)                 0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5)                 30        \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 18        \n",
            "=================================================================\n",
            "Total params: 98\n",
            "Trainable params: 98\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 18402 samples, validate on 5520 samples\n",
            "Epoch 1/2\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "18402/18402 [==============================] - 11s 574us/step - loss: nan - acc: 0.0047 - val_loss: nan - val_acc: 0.0045\n",
            "Epoch 2/2\n",
            "18402/18402 [==============================] - 10s 535us/step - loss: nan - acc: 0.0047 - val_loss: nan - val_acc: 0.0045\n",
            "[[nan nan nan]\n",
            " [nan nan nan]\n",
            " [nan nan nan]\n",
            " ...\n",
            " [nan nan nan]\n",
            " [nan nan nan]\n",
            " [nan nan nan]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_S8wTbzdH-d",
        "colab_type": "code",
        "outputId": "22e82c1b-eeeb-4737-88a0-1866ad1c4c4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "\n",
        "model2 = Sequential()\n",
        "\n",
        "model2.add(LSTM(32, input_shape=(3, 4)))\n",
        "# Optional: model.add(BatchNormalization())\n",
        "model2.add(Dropout(0.2))\n",
        "\n",
        "model2.add(Dense(3, activation='sigmoid'))\n",
        "model2.summary()\n",
        "\n",
        "model2.compile( loss='categorical_crossentropy',\n",
        " optimizer='Adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 32)                4736      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 4,835\n",
            "Trainable params: 4,835\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Or52nPUUYaII",
        "colab_type": "code",
        "outputId": "ed943444-fd94-46a5-d24f-8710b650c03a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "# Training the model\n",
        "history2 = model2.fit( X_train2, y_train2,\n",
        " validation_data=(X_val2, y_val2),\n",
        " epochs=1)\n",
        "\n",
        "y_prediction2 = model2. predict(X_test2)\n",
        "print(y_prediction2)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 18402 samples, validate on 5520 samples\n",
            "Epoch 1/1\n",
            "18402/18402 [==============================] - 3s 172us/step - loss: 0.1558 - acc: 0.9727 - val_loss: 0.0545 - val_acc: 0.9817\n",
            "[[0.00274855 0.03243083 0.853155  ]\n",
            " [0.00757658 0.07545894 0.7113829 ]\n",
            " [0.00333911 0.00499663 0.9071179 ]\n",
            " ...\n",
            " [0.00333962 0.00499701 0.90711206]\n",
            " [0.00334141 0.00499844 0.90708786]\n",
            " [0.00333943 0.00499688 0.90711504]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8bKfdkVHPQD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import folium\n",
        "from folium import plugins"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQnYlo2XgGzd",
        "colab_type": "code",
        "outputId": "c7c0c005-ec35-4d7a-fa06-2773421d9aee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        }
      },
      "source": [
        "# convert form sigmoid result to [0,0,1]\n",
        "y_pred_single = [np.argmax(p) for p in y_prediction]\n",
        "y_test_single=[np.argmax(p) for p in y_test]\n",
        "y_pred_single2 = [np.argmax(p) for p in y_prediction2]\n",
        "y_test_single2=[np.argmax(p) for p in y_test2]\n",
        "\n",
        "r1 = classification_report(y_test_single, y_pred_single)\n",
        "print('Report for CNN is!!\\n', r1)\n",
        "r2 = classification_report(y_test_single2, y_pred_single2)\n",
        "print('Report for LSTM is!!\\n', r2)\n",
        "conf1 = confusion_matrix(y_test_single, y_pred_single)\n",
        "print('Confusion Matrix for CNN is!!\\n', conf1)\n",
        "conf2 = confusion_matrix(y_test_single2, y_pred_single2)\n",
        "print('Confusion Matrix for LSTM is!!\\n', conf2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Report for CNN is!!\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      1.00      0.01         7\n",
            "           1       0.00      0.00      0.00        66\n",
            "           2       0.00      0.00      0.00      2294\n",
            "\n",
            "    accuracy                           0.00      2367\n",
            "   macro avg       0.00      0.33      0.00      2367\n",
            "weighted avg       0.00      0.00      0.00      2367\n",
            "\n",
            "Report for LSTM is!!\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         7\n",
            "           1       0.82      0.55      0.65        66\n",
            "           2       0.99      1.00      0.99      2294\n",
            "\n",
            "    accuracy                           0.98      2367\n",
            "   macro avg       0.60      0.51      0.55      2367\n",
            "weighted avg       0.98      0.98      0.98      2367\n",
            "\n",
            "Confusion Matrix for CNN is!!\n",
            " [[   7    0    0]\n",
            " [  66    0    0]\n",
            " [2294    0    0]]\n",
            "Confusion Matrix for LSTM is!!\n",
            " [[   0    5    2]\n",
            " [   0   36   30]\n",
            " [   0    3 2291]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2iUnwRrgK4C",
        "colab_type": "code",
        "outputId": "a926f984-ef70-45b2-ebf7-a7822f216c0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "\n",
        "model = KerasClassifier(build_fn=model1func)\n",
        "\n",
        "k = 5\n",
        "seed = 11\n",
        "skfold = model_selection.StratifiedKFold(n_splits=k, shuffle = True,\n",
        "random_state=seed)\n",
        "batch_size = [10, 20, 40, 60, 80, 100]\n",
        "epochs = [10, 50, 100]\n",
        "optimizers = ['adam','adadelta']\n",
        "\n",
        "param_grid = dict(batch_size=batch_size, \\\n",
        "    epochs=epochs, optimizer=optimizers)\n",
        "\n",
        "gsCV_model = model_selection.GridSearchCV(estimator=model,\\\n",
        "param_grid=param_grid, n_jobs=2, cv=skfold, scoring='accuracy')\n",
        "\n",
        "a, b = y_train.shape\n",
        "y_train_1D = []\n",
        "for i in range(a):\n",
        "    for j in range(b):\n",
        "        if y_train[i][j] == 1:\n",
        "            y_train_1D.append(j)\n",
        "\n",
        "y_train = np.array(y_train_1D)\n",
        "print(y_train, y_train.shape)\n",
        "gsCV_model.fit(X_train, y_train)\n",
        "\n",
        "gridsearch_result = pd.DataFrame(gsCV_model.cv_results_)\n",
        "print(gridsearch_result)\n",
        "gridsearch_result.to_csv('FileLab3.csv')\n",
        "\n",
        "print(gsCV_model.best_params_)\n",
        "print(gsCV_model.best_score_)\n",
        "\n",
        "a, b = y_test.shape\n",
        "y_test_1D = []\n",
        "for i in range(a):\n",
        "    for j in range(b):\n",
        "        if y_test[i][j] == 1:\n",
        "            y_test_1D.append(j)\n",
        "\n",
        "y_prediction_best_param = gsCV_model.predict(X_test)\n",
        "\n",
        "print('before', y_prediction)\n",
        "print('After', y_prediction_best_param)\n",
        "\n",
        "r1_b = classification_report(y_test_1D, y_prediction_best_param)\n",
        "conf1_b = confusion_matrix(y_test_1D, y_prediction_best_param)\n",
        "print('before', r1)\n",
        "print(conf1)\n",
        "print('After', r1_b)\n",
        "print(conf1_b)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2 2 2 ... 2 2 2] (18402,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stM1XdummrbW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
